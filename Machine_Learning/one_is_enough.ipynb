{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the plot for the k value vs rate of error\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,60),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=8)\n",
    "plt.title('Error Rate vs. K Value', fontsize=20)\n",
    "plt.xlabel('K',fontsize=15)\n",
    "plt.ylabel('Error (misclassification) Rate',fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the pairplot using the seaborn\n",
    "sns.pairplot(data=df[df.columns[1:]],diag_kws={'edgecolor':'k','bins':25},plot_kws={'edgecolor':'k'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the subplots\n",
    "f,(ax1, ax2) = plt.subplots(1, 2, sharey=True,figsize=(12,6))\n",
    "ax1.scatter(df['mean area'],df['Cancer'])\n",
    "ax1.set_title(\"Cancer cases as a function of mean area\", fontsize=15)\n",
    "ax2.scatter(df['mean smoothness'],df['Cancer'])\n",
    "ax2.set_title(\"Cancer cases as a function of mean smoothness\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You get the data but it is not the Data Frame so you have to convert it into the DataFrame which is also important\n",
    "df=pd.DataFrame(data=X,columns=['X'+str(i) for i in range(1,11)])\n",
    "df['y']=pd.Series(y)\n",
    "df.head()\n",
    "\n",
    "#Nice Looking data Structure now in the house so keep exploring which is very important \n",
    "#There is one thing code code code that no one teach you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the Boxplot for all the columns in a dataset\n",
    "#which is a description of the percentiles \n",
    "#give the best visualization for the outliers which is very important to see\n",
    "i=1\n",
    "plt.figure(figsize=(20,20))\n",
    "for c in df.columns[:-1]:\n",
    "    plt.subplot(4,3,i)\n",
    "    plt.title(f\"Boxplot of {c}\",fontsize=16)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    sns.boxplot(y=df[c],x=df['y'])\n",
    "    i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can do sampling from the data as the sampling is the key in statistics which is very important\n",
    "#and we have to find the easiest way in the language to implement the things what we want...\n",
    "df_sample=df.sample(frac=0.01)\n",
    "print('----------------Size of the sample----------------')\n",
    "print(df_sample)\n",
    "\n",
    "\n",
    "#setting the style for the seaborn \n",
    "sns.set(style=\"ticks\")\n",
    "g=sns.pairplot(df_sample,vars=[\"X1\",\"X2\",\"X3\"],\n",
    "               hue=\"y\",markers=[\"o\", \"s\"],\n",
    "               diag_kind=\"kde\",diag_kws=dict(shade=True),plot_kws=dict(s=100,alpha=0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is nothing but separating the data\n",
    "X=df.drop('y',axis=1)\n",
    "y=df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "r=minimize_scalar(objective,bounds=(2,21),options={'disp':True},method='Bounded')\n",
    "r.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_dataset(x, X_train,y_train,X_val,y_val,v_th=0.5,alpha=3,beta=1):\n",
    "    \"\"\"\n",
    "    Objective function computing a overall cost function\n",
    "    involving the running time and performance of the AdaBoost classifier fitting\n",
    "    x: number of trees to be used by the meta-estimator (AdaBoost)\n",
    "    V_th: Minimum accuracy threshold\n",
    "    alpha: Cost factor of the accuracy (indicator of profit)\n",
    "    beta: Cost factor of running time (indicator of expense)\n",
    "    \"\"\" \n",
    "    x = int(x)\n",
    "    if x<1:\n",
    "        x=1\n",
    "    t1=time.time()\n",
    "    # Fitting\n",
    "    adaboost = AdaBoostClassifier(DecisionTreeClassifier(min_samples_leaf=20,max_depth=2),\n",
    "                            n_estimators=x,learning_rate=0.2)\n",
    "    adaboost.fit(X_train,y_train)\n",
    "    t2=time.time()\n",
    "    pred_train = adaboost.predict(X_train)\n",
    "    pred_val = adaboost.predict(X_val)\n",
    "    # Accuracy and F1 score\n",
    "    acc_train=accuracy_score(y_train,pred_train)\n",
    "    f1_train = f1_score(y_train,pred_train,average='micro')\n",
    "    acc_val=accuracy_score(y_val,pred_val)\n",
    "    f1_val = f1_score(y_val,pred_val,average='micro')\n",
    "    \n",
    "    v = acc_val # Validation set accuracy\n",
    "    t = t2-t1 # Time taken for fitting and calculating the accuracy\n",
    "    \n",
    "    # Normalize the accuracy and time measures\n",
    "    #v=(v-v_th)/v.max()\n",
    "    #t=t/t.max()\n",
    "    \n",
    "    # Objective function (a profit measure)\n",
    "    obj = alpha*v-beta*(t)\n",
    "    \n",
    "    return -float(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value_counts() is a special function that helps in getting a unique value count in a database which is very important\n",
    "#we are counting the credit policy status like how many loans have approved and how many are not \n",
    "#using the function value_counts()\n",
    "print(\"Follwoing is a breakup of credit approval status. 1 means approved credit, 0 means not approved.\")\n",
    "print(df['credit.policy'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram\n",
    "\n",
    "# you are simply taking the people credit score and want to make a comparison\n",
    "# it is very important histogram code which does not \n",
    "\n",
    "df[df['credit.policy']==1]['fico'].plot.hist(bins=30,alpha=0.5,color='blue', label='Credit.Policy=1')\n",
    "\n",
    "df[df['credit.policy']==0]['fico'].plot.hist(bins=30,alpha=0.5, color='red', label='Credit.Policy=0')\n",
    "\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "plt.title (\"Histogram of FICO score by approved or disapproved credit policies\", fontsize=16)\n",
    "\n",
    "plt.xlabel(\"FICO score\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOXPlot\n",
    "#plotting the boxplot using the credit \n",
    "# it is even \n",
    "sns.boxplot(x=df['credit.policy'],y=df['int.rate'])\n",
    "\n",
    "plt.title(\"Interest rate varies between risky and non-risky borrowers\", fontsize=15)\n",
    "\n",
    "plt.xlabel(\"Credit policy\",fontsize=15)\n",
    "\n",
    "plt.ylabel(\"Interest rate\",fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''-----------------------------joint plot-------------------distribution as well as scatterplot '''\n",
    "#We are trying to find a trend between the fico score and the interest rate that is \n",
    "#why it is called the joint plot because it is the combination of the distribution and the scatterplot\n",
    "sns.jointplot(x='fico',y='int.rate',data=df, color='purple', size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### For `LogisticRegression` estimator, there is a special `predict_proba` method which computes the raw probability values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the prob_threshold\n",
    "prob_threshold = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is very important to see this raw matching of the output\n",
    "prob_df=pd.DataFrame(clf1.predict_proba(X_test[:10]),columns=['Prob of NO','Prob of YES'])\n",
    "prob_df['Decision']=(prob_df['Prob of YES']>prob_threshold).apply(int)\n",
    "prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = [0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.25,1.5,1.75,2.0]\n",
    "n_clusters = []\n",
    "for i in noise:\n",
    "    centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "    X, labels_true = make_blobs(n_samples=200, centers=centers, cluster_std=i,random_state=101)\n",
    "    af_model=AffinityPropagation(preference=-50,max_iter=500,convergence_iter=15,damping=0.9).fit(X)\n",
    "    n_clusters.append(len(af_model.cluster_centers_indices_))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = [10,20,50,100,200,500,1000,2000,3000,5000,7500,10000]\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "t_aff = []\n",
    "homo_aff=[]\n",
    "complete_aff=[]\n",
    "\n",
    "for i in tqdm(n_samples):\n",
    "    X,labels_true = make_blobs(n_samples=i, centers=centers, cluster_std=0.5,random_state=0)\n",
    "    t1 = time.time()\n",
    "    af_model = AffinityPropagation(preference=-50,max_iter=50).fit(X)\n",
    "    t2=time.time()\n",
    "    t_aff.append(t2-t1)\n",
    "    homo_aff.append(metrics.homogeneity_score(labels_true,af_model.labels_))\n",
    "    complete_aff.append(metrics.completeness_score(labels_true,af_model.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the misclassification error rate\n",
    "#finding the misclassification error rate\n",
    "print(\"Misclassification error rate:\",round(np.mean(pred!=y_test),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the missing value if it is the easiest way\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying a particular function to a column usng the apply function\n",
    "df['response']=df['response'].apply(class_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not only heads but the sample function also used to get the sample from the dataframe\n",
    "df_dummies.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
