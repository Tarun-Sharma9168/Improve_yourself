{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "## Name:Tarun Sharma\n",
    "## Date:30 Aug 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : \n",
    "Write a python code that reads a directory, lists all the files found in that directory, and returns metadata about the files (filename, filetype, filesize (MB/KB/etc.), Author, Creation Date, Last Modified Date, …).\n",
    " \n",
    "These should be output as a csv file, with 1 file per row.  It should be tested against a variety of files: JPG, PNG, .XLSX, …others?\n",
    " \n",
    "The code should be written as a function that can be called, where it takes as input the working directory of interest, and any other pertinent parameters.  It should return a CSV file as output, whose name should be specified as a parameter input to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import os.path\n",
    "\n",
    "import time\n",
    "\n",
    "from os import stat\n",
    "\n",
    "from pwd import getpwuid\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Function which returns the data frame which contains the attributes and stores the csv file of all attributes\n",
    "def attr_file(directory_name):\n",
    "    main_list=[]\n",
    "    \n",
    "    entries=os.listdir(directory_name)\n",
    "    \n",
    "    for i in range(len(entries)):\n",
    "        small_dir=[]\n",
    "        __file__=entries[i]\n",
    "        #File Name\n",
    "        File         = __file__\n",
    "        small_dir.append(File)\n",
    "        \n",
    "        #File Type\n",
    "        File_Type    =__file__.split('.')[1]\n",
    "        small_dir.append(File_Type)\n",
    "        \n",
    "        #Access Time\n",
    "        Access_time  = time.ctime(os.path.getatime(__file__))\n",
    "        small_dir.append(Access_time)\n",
    "        \n",
    "        #Change_time\n",
    "        Change_time  = time.ctime(os.path.getctime(__file__))\n",
    "        small_dir.append(Change_time)\n",
    "       \n",
    "        #File Size\n",
    "        File_Size         = os.path.getsize(__file__)\n",
    "        small_dir.append(File_Size)\n",
    "        \n",
    "        #Last Modified Time\n",
    "        Last_modified= time.ctime(os.path.getmtime(__file__))\n",
    "        small_dir.append(Last_modified)\n",
    "        \n",
    "        #Creation Time\n",
    "        Created      = time.ctime(os.path.getctime(__file__))\n",
    "        small_dir.append(Created)\n",
    "        \n",
    "        #Author Name\n",
    "        Author_Name  = getpwuid(stat(__file__).st_uid).pw_name\n",
    "        small_dir.append(Author_Name)\n",
    "        \n",
    "        \n",
    "        main_list.append(small_dir)\n",
    "        \n",
    "    \n",
    "    data=pd.DataFrame(main_list,columns=['File_Name','File_Type','Access_Time','Change_Time','File_Size','Last_Modified_Time','Creation_Time','Author_Name'])\n",
    "    \n",
    "    data.to_csv('file_attributes.csv')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>File_Type</th>\n",
       "      <th>Access_Time</th>\n",
       "      <th>Change_Time</th>\n",
       "      <th>File_Size</th>\n",
       "      <th>Last_Modified_Time</th>\n",
       "      <th>Creation_Time</th>\n",
       "      <th>Author_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i-am-iron-man-avengers-endgame-u4.jpg</td>\n",
       "      <td>jpg</td>\n",
       "      <td>Sun Aug 30 12:25:06 2020</td>\n",
       "      <td>Sun Aug 30 12:25:06 2020</td>\n",
       "      <td>490128</td>\n",
       "      <td>Wed Jul 29 19:46:16 2020</td>\n",
       "      <td>Sun Aug 30 12:25:06 2020</td>\n",
       "      <td>tarun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>database_thirs.png</td>\n",
       "      <td>png</td>\n",
       "      <td>Sun Aug 30 12:25:06 2020</td>\n",
       "      <td>Sun Aug 30 12:25:06 2020</td>\n",
       "      <td>43811</td>\n",
       "      <td>Wed Jan 29 19:59:22 2020</td>\n",
       "      <td>Sun Aug 30 12:25:06 2020</td>\n",
       "      <td>tarun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tp.txt</td>\n",
       "      <td>txt</td>\n",
       "      <td>Sun Aug 30 11:38:57 2020</td>\n",
       "      <td>Sun Aug 30 11:48:03 2020</td>\n",
       "      <td>44</td>\n",
       "      <td>Sat Aug 29 23:30:55 2020</td>\n",
       "      <td>Sun Aug 30 11:48:03 2020</td>\n",
       "      <td>tarun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abalone.csv</td>\n",
       "      <td>csv</td>\n",
       "      <td>Sun Aug 30 12:25:44 2020</td>\n",
       "      <td>Sun Aug 30 12:25:44 2020</td>\n",
       "      <td>191962</td>\n",
       "      <td>Wed Oct  2 14:33:12 2019</td>\n",
       "      <td>Sun Aug 30 12:25:44 2020</td>\n",
       "      <td>tarun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.ipynb_checkpoints</td>\n",
       "      <td>ipynb_checkpoints</td>\n",
       "      <td>Sun Aug 30 11:50:43 2020</td>\n",
       "      <td>Sun Aug 30 11:51:05 2020</td>\n",
       "      <td>4096</td>\n",
       "      <td>Sun Aug 30 11:51:05 2020</td>\n",
       "      <td>Sun Aug 30 11:51:05 2020</td>\n",
       "      <td>tarun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Assignment_DataScience.ipynb</td>\n",
       "      <td>ipynb</td>\n",
       "      <td>Sun Aug 30 12:28:43 2020</td>\n",
       "      <td>Sun Aug 30 12:28:43 2020</td>\n",
       "      <td>11644</td>\n",
       "      <td>Sun Aug 30 12:28:43 2020</td>\n",
       "      <td>Sun Aug 30 12:28:43 2020</td>\n",
       "      <td>tarun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31119028_group1.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>Sun Aug 30 12:25:06 2020</td>\n",
       "      <td>Sun Aug 30 12:25:06 2020</td>\n",
       "      <td>584521</td>\n",
       "      <td>Thu Jul 23 10:00:30 2020</td>\n",
       "      <td>Sun Aug 30 12:25:06 2020</td>\n",
       "      <td>tarun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abalone.data</td>\n",
       "      <td>data</td>\n",
       "      <td>Sun Aug 30 12:25:44 2020</td>\n",
       "      <td>Sun Aug 30 12:25:44 2020</td>\n",
       "      <td>191873</td>\n",
       "      <td>Wed Jan 15 12:35:39 2020</td>\n",
       "      <td>Sun Aug 30 12:25:44 2020</td>\n",
       "      <td>tarun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ICC Test Bat 3001.xlsx</td>\n",
       "      <td>xlsx</td>\n",
       "      <td>Sun Aug 30 12:28:32 2020</td>\n",
       "      <td>Sun Aug 30 12:28:32 2020</td>\n",
       "      <td>406671</td>\n",
       "      <td>Fri Jan  3 12:27:56 2020</td>\n",
       "      <td>Sun Aug 30 12:28:32 2020</td>\n",
       "      <td>tarun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>recipes.json</td>\n",
       "      <td>json</td>\n",
       "      <td>Sun Aug 30 12:27:38 2020</td>\n",
       "      <td>Sun Aug 30 12:27:38 2020</td>\n",
       "      <td>2626853</td>\n",
       "      <td>Sun Oct 13 19:14:30 2019</td>\n",
       "      <td>Sun Aug 30 12:27:38 2020</td>\n",
       "      <td>tarun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               File_Name          File_Type  \\\n",
       "0  i-am-iron-man-avengers-endgame-u4.jpg                jpg   \n",
       "1                     database_thirs.png                png   \n",
       "2                                 tp.txt                txt   \n",
       "3                            abalone.csv                csv   \n",
       "4                     .ipynb_checkpoints  ipynb_checkpoints   \n",
       "5           Assignment_DataScience.ipynb              ipynb   \n",
       "6                    31119028_group1.pdf                pdf   \n",
       "7                           abalone.data               data   \n",
       "8                 ICC Test Bat 3001.xlsx               xlsx   \n",
       "9                           recipes.json               json   \n",
       "\n",
       "                Access_Time               Change_Time  File_Size  \\\n",
       "0  Sun Aug 30 12:25:06 2020  Sun Aug 30 12:25:06 2020     490128   \n",
       "1  Sun Aug 30 12:25:06 2020  Sun Aug 30 12:25:06 2020      43811   \n",
       "2  Sun Aug 30 11:38:57 2020  Sun Aug 30 11:48:03 2020         44   \n",
       "3  Sun Aug 30 12:25:44 2020  Sun Aug 30 12:25:44 2020     191962   \n",
       "4  Sun Aug 30 11:50:43 2020  Sun Aug 30 11:51:05 2020       4096   \n",
       "5  Sun Aug 30 12:28:43 2020  Sun Aug 30 12:28:43 2020      11644   \n",
       "6  Sun Aug 30 12:25:06 2020  Sun Aug 30 12:25:06 2020     584521   \n",
       "7  Sun Aug 30 12:25:44 2020  Sun Aug 30 12:25:44 2020     191873   \n",
       "8  Sun Aug 30 12:28:32 2020  Sun Aug 30 12:28:32 2020     406671   \n",
       "9  Sun Aug 30 12:27:38 2020  Sun Aug 30 12:27:38 2020    2626853   \n",
       "\n",
       "         Last_Modified_Time             Creation_Time Author_Name  \n",
       "0  Wed Jul 29 19:46:16 2020  Sun Aug 30 12:25:06 2020       tarun  \n",
       "1  Wed Jan 29 19:59:22 2020  Sun Aug 30 12:25:06 2020       tarun  \n",
       "2  Sat Aug 29 23:30:55 2020  Sun Aug 30 11:48:03 2020       tarun  \n",
       "3  Wed Oct  2 14:33:12 2019  Sun Aug 30 12:25:44 2020       tarun  \n",
       "4  Sun Aug 30 11:51:05 2020  Sun Aug 30 11:51:05 2020       tarun  \n",
       "5  Sun Aug 30 12:28:43 2020  Sun Aug 30 12:28:43 2020       tarun  \n",
       "6  Thu Jul 23 10:00:30 2020  Sun Aug 30 12:25:06 2020       tarun  \n",
       "7  Wed Jan 15 12:35:39 2020  Sun Aug 30 12:25:44 2020       tarun  \n",
       "8  Fri Jan  3 12:27:56 2020  Sun Aug 30 12:28:32 2020       tarun  \n",
       "9  Sun Oct 13 19:14:30 2019  Sun Aug 30 12:27:38 2020       tarun  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_file('../tarun_30_08_2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question1: \n",
    "\n",
    "Consider the matrix below\n",
    "Write down a python program \n",
    "\n",
    "• To replace the number “1” in first row of matrix with the value in next row (i.e. second row in the matrix) below the number “1” (i.e. value below are “d” & “f”). \n",
    " \n",
    "• To replace the number “2” in third row of matrix with the value in previous row (i.e. second row in the matrix ) above the number “2” (i.e. value below is “b”). \n",
    "    \n",
    "• To replace the number “3” in row fifth of the matrix with the sum of values at the corner of the matrix (i.e. a+ f+ f+ e).\n",
    "\n",
    "The code should be written as a function that can be called whenever we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values(mat):\n",
    "    \n",
    "    #instead of iterating in this way we can also directly do \n",
    "    #but we can make it little generalise\n",
    "    #it is O(N)\n",
    "    #And We can do this in O(1) here by directly assigning the value \n",
    "    \n",
    "    #first step\n",
    "    for i in range(len(mat)):\n",
    "        if(mat[0][i]=='1'):\n",
    "            mat[0][i]=mat[1][i]\n",
    "\n",
    "\n",
    "        #Second step\n",
    "    for i in range(len(mat)):\n",
    "        if(mat[2][i]=='2'):\n",
    "            mat[2][i]=mat[1][i]\n",
    "\n",
    "\n",
    "        #Third Step\n",
    "    for i in range(len(mat)):\n",
    "        if(mat[4][i]=='3'):\n",
    "            mat[4][i]=mat[0][0]+mat[0][len(mat)-1]+mat[len(mat)-1][0]+mat[len(mat)-1][len(mat)-1]\n",
    "        \n",
    "    \n",
    "    return mat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'b', '1', 'd', '1', 'f'],\n",
       " ['b', 'c', 'd', 'e', 'f', 'a'],\n",
       " ['2', 'd', 'e', 'f', 'a', 'b'],\n",
       " ['d', 'e', 'f', 'a', 'b', 'c'],\n",
       " ['e', 'f', 'a', '3', 'c', 'd'],\n",
       " ['f', 'a', 'b', 'c', 'd', 'e']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = [ ['a','b','1','d','1','f'],\n",
    "        ['b','c','d','e','f','a'],\n",
    "        ['2','d','e','f','a','b'],\n",
    "        ['d','e','f','a','b','c'],\n",
    "        ['e','f','a','3','c','d'],\n",
    "        ['f','a','b','c','d','e']\n",
    "      ]\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'b', 'd', 'd', 'f', 'f'],\n",
       " ['b', 'c', 'd', 'e', 'f', 'a'],\n",
       " ['b', 'd', 'e', 'f', 'a', 'b'],\n",
       " ['d', 'e', 'f', 'a', 'b', 'c'],\n",
       " ['e', 'f', 'a', 'affe', 'c', 'd'],\n",
       " ['f', 'a', 'b', 'c', 'd', 'e']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_values(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Write a bash or shell script to install simulation tool Netlogo on centos7?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---installing directly-----\n",
    "---Write this commands in terminal--------\n",
    "\n",
    "---------installing-----------\n",
    "#sudo yum install netlogo\n",
    "\n",
    "--------opening---------------\n",
    "\n",
    "#netlogo\n",
    "\n",
    "\n",
    "\n",
    "-----by netlogo official website-----------\n",
    "-------installing-------------\n",
    "\n",
    "#wget url_of_download\n",
    "\n",
    "#tar -xvzf compresses_file\n",
    "\n",
    "#./netlogo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Explain Natural language processing and natural language generation via process flow along with python library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing\n",
    "\n",
    "Computers and machines are great at working with tabular data or spreadsheets. However, as human beings generally communicate in words and sentences, not in the form of tables. Much information that humans speak or write is unstructured. So it is not very clear for computers to interpret such. In natural language processing (NLP), \n",
    "the goal is to make computers\n",
    "understand the unstructured text and retrieve meaningful pieces of informationComputers and machines are great at working with tabular data or spreadsheets. However, as human beings generally communicate in words and sentences, not in the form of tables. Much information that humans speak or write is unstructured. So it is not very clear for computers to interpret such. In natural language processing (NLP), the goal is to make computers understand the unstructured text and retrieve meaningful pieces of information from it. Natural language Processing (NLP) is a subfield of artificial intelligence, in which its depth involves the interactions between computers and humans. \n",
    "from it. Natural language Processing (NLP) is a subfield of artificial \n",
    "intelligence, in which its depth involves the interactions between computers and humans.\n",
    "\n",
    "\n",
    "**Applications of NLP**:\n",
    "\n",
    "Machine Translation,\n",
    "Speech Recognition,\n",
    "Sentiment Analysis,\n",
    "Question Answering,\n",
    "Summarization of Text,\n",
    "Chatbot,\n",
    "Intelligent Systems,\n",
    "Text Classifications,\n",
    "Character Recognition,\n",
    "Spell Checking,\n",
    "Spam Detection,\n",
    "Autocomplete,\n",
    "Named Entity Recognition,\n",
    "Predictive Typing\n",
    "\n",
    "\n",
    "**Rule-based Natural Language Processing**:\n",
    "It uses common sense reasoning for processing tasks. For instance, the freezing temperature can lead to death, or hot coffee can burn people’s skin, along with other common sense reasoning tasks. However, this process can take much time, and it requires manual effort.\n",
    "\n",
    "\n",
    "**Statistical Natural Language Processing**:\n",
    "It uses large amounts of data and tries to derive conclusions from it. Statistical NLP uses machine learning algorithms to train NLP models. After successful training on large amounts of data, the trained model will have positive outcomes with deduction.\n",
    "\n",
    "\n",
    "**Steps in NLP**\n",
    "1)Lexical Analysis\n",
    "2)Syntactic Analysis\n",
    "3)Semantic Analysis\n",
    "4)Disclosure Analysis\n",
    "5)Pragmatic Analysis\n",
    "\n",
    "\n",
    "\n",
    "**Current challenges in NLP:**\n",
    "\n",
    "**Breaking sentences into tokens,\n",
    "  Tagging parts of speech (POS),\n",
    "  Building an appropriate vocabulary,\n",
    "  Linking the components of a created vocabulary,\n",
    "  Understanding the context,\n",
    "  Extracting semantic meaning,\n",
    "  Named Entity Recognition (NER),\n",
    "  Transforming unstructured data into structured data,\n",
    "  Ambiguity in speech**\n",
    "  \n",
    "  \n",
    "**Easy to use NLP libraries:**\n",
    "\n",
    "1)NLTK\n",
    "2)Spacy\n",
    "3)Gensim\n",
    "4)TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Task of Generating language from Machine representation .\n",
    "\n",
    "NLG is a software process where structured data is transformed into Natural Conversational Language for output to the user. In other words, structured data is presented in an unstructured manner to the user. Think of NLG is the inverse of NLU.\n",
    "\n",
    "With NLU we are taking the unstructured conversational input from the user (natural language) and structuring it for our software process. With NLG, we are taking structured data from backend and state machines, and turning this into unstructured data. Conversational output in human language.\n",
    "\n",
    "\n",
    "Natural Language Generation (NLG) is a subfield of Natural Language Processing (NLP) that is concerned with the automatic generation of human-readable text by a computer. NLG is used across a wide range of NLP tasks such as Machine Translation, Speech-to-text, chatbots, text auto-correct, or text auto-completion.\n",
    "\n",
    "We can model NLG with the help of Language Modeling. Let me explain the concept of language models – A language model learns to predict the probability of a sequence of words.\n",
    "\n",
    "Types of Language Models\n",
    "The following are the two types of Language Models:\n",
    "\n",
    "**Statistical Language Models:** These models use traditional statistical techniques like N-grams, Hidden Markov Models (HMM), and certain linguistic rules to learn the probability distribution of words.\n",
    "\n",
    "\n",
    "**Neural Language Models:** These models have surpassed the statistical language models in their effectiveness. They use different kinds of Neural Networks to model language.\n",
    "\n",
    "Basic NN which is used is the LSTM,GRU and other transformer architecture nowadays which are popular,in languages BERT,ALBERT and other kinds of BERT like FINBERT(Financial BERT) ,XLNET,GPT2/3 are other useful architectures which are popular nowadays.\n",
    "\n",
    "Tools used is Pytorch,Tensorflow and others ans also pretrained word embeddings is also needed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
